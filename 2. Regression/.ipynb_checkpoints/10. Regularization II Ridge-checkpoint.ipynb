{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization II: Ridge\n",
    "Lasso is great for feature selection, but when building regression models, Ridge regression should be your first choice.\n",
    "\n",
    "Recall that lasso performs regularization by adding to the loss function a penalty term of the absolute value of each coefficient multiplied by some alpha. This is also known as L1 regularization because the regularization term is the L1 norm of the coefficients. This is not the only way to regularize, however.\n",
    "\n",
    "If instead you took the sum of the squared values of the coefficients multiplied by some alpha - like in Ridge regression - you would be computing the L2 norm. In this exercise, you will practice fitting ridge regression models over a range of different alphas, and plot cross-validated R2 scores for each, using this function that we have defined for you, which plots the R2 score as well as standard error for each alpha:\n",
    "\n",
    "def display_plot(cv_scores, cv_scores_std):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(alpha_space, cv_scores)\n",
    "\n",
    "    std_error = cv_scores_std / np.sqrt(10)\n",
    "\n",
    "    ax.fill_between(alpha_space, cv_scores + std_error, cv_scores - std_error, alpha=0.2)\n",
    "    ax.set_ylabel('CV Score +/- Std Error')\n",
    "    ax.set_xlabel('Alpha')\n",
    "    ax.axhline(np.max(cv_scores), linestyle='--', color='.5')\n",
    "    ax.set_xlim([alpha_space[0], alpha_space[-1]])\n",
    "    ax.set_xscale('log')\n",
    "    plt.show()\n",
    "    \n",
    "Don't worry about the specifics of the above function works. The motivation behind this exercise is for you to see how the R2 score varies with different alphas, and to understand the importance of selecting the right value for alpha. You'll learn how to tune alpha in the next chapter.\n",
    "\n",
    "Instructions\n",
    "\n",
    "* Instantiate a Ridge regressor and specify normalize=True.\n",
    "Inside the for loop:\n",
    "* Specify the alpha value for the regressor to use.\n",
    "* Perform 10-fold cross-validation on the regressor with the specified alpha. The data is available in the arrays X and y.\n",
    "Append the average and the standard deviation of the computed cross-validated scores. NumPy has been pre-imported for you as np.\n",
    "* Use the display_plot() function to visualize the scores and standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Read the CSV file into a DataFrame: df\n",
    "df = pd.read_csv('boston.csv')\n",
    "df.head()\n",
    "df_columns=df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.TAX.values.reshape(-1,1)\n",
    "X=df.AGE.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'display_plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-15a9d620ec10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# Display the plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mdisplay_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mridge_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mridge_scores_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'display_plot' is not defined"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Setup the array of alphas and lists to store scores\n",
    "alpha_space = np.logspace(-4, 0, 50)\n",
    "ridge_scores = []\n",
    "ridge_scores_std = []\n",
    "alpha=1\n",
    "# Create a ridge regressor: ridge\n",
    "ridge = Ridge(normalize=True)\n",
    "\n",
    "# Compute scores over range of alphas\n",
    "for alpha in alpha_space:\n",
    "\n",
    "    # Specify the alpha value to use: ridge.alpha\n",
    "    ridge.alpha = alpha\n",
    "    \n",
    "    # Perform 10-fold CV: ridge_cv_scores\n",
    "    ridge_cv_scores = cross_val_score(ridge, X, y, cv=10)\n",
    "    \n",
    "    # Append the mean of ridge_cv_scores to ridge_scores\n",
    "    ridge_scores.append(np.mean(ridge_cv_scores))\n",
    "    \n",
    "    # Append the std of ridge_cv_scores to ridge_scores_std\n",
    "    ridge_scores_std.append(np.std(ridge_cv_scores))\n",
    "\n",
    "# Display the plot\n",
    "display_plot(ridge_scores, ridge_scores_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
